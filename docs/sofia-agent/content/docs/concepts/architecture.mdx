---
title: Architecture Overview
description: Understanding SOFIA's system architecture and core components
---

# Architecture Overview

SOFIA is designed with a modular architecture that separates concerns and allows for easy extension and customization. This page provides an overview of the key components and how they work together.

## System Components

SOFIA consists of several core components:

<Mermaid
  chart="
  flowchart TB
    Agent[Sofia Agent] --> LLM[LLM Provider]
    Agent --> Steps[Steps & Routes]
    Agent --> Tools[Tools]
    Session[Flow Session] --> Agent
    Session --> History[Session History]
    Client[User/Client] --> Session"
/>

### Sofia Agent

The `Sofia` class is the main interface for creating and managing agents. It:

- Holds the configuration for the agent
- Manages steps and routes
- Registers tools
- Creates sessions
- Validates the agent configuration

### Steps and Routes

Steps define the discrete states an agent can be in. Each step:

- Has a unique ID
- Contains a description of its purpose
- Specifies available tools for that step
- Defines routes to other steps

Routes control transitions between steps:

- Each route points to a target step
- Routes have conditions that determine when to transition
- The LLM decides which route to take based on user input

### Tools

Tools are functions that the agent can call to perform actions:

- Can be custom Python functions
- Can be standard library functions referenced via `package_name:function` syntax
- Have documentation generated from docstrings
- Support parameter validation

### LLM Provider

The LLM provider is the interface to the language model:

- Supports OpenAI, Mistral, and Gemini
- Handles prompting and response parsing
- Creates structured outputs for decisions

### Flow Session

Sessions manage the state of an agent conversation:

- Track the current step
- Maintain conversation history
- Handle tool calls
- Manage transitions between steps

## Execution Flow

<Mermaid
  chart="
  sequenceDiagram
    participant User
    participant Session as FlowSession
    participant LLM
    participant Tools
    
    User->>Session: Input message
    Session->>Session: Add message to history
    Session->>LLM: Request next decision
    LLM->>Session: Return decision
    
    alt Decision is to speak
        Session->>User: Return agent message
    else Decision is to call tool
        Session->>Tools: Execute tool with arguments
        Tools->>Session: Return tool result
        Session->>LLM: Request next decision with tool result
        LLM->>Session: Return decision
        Session->>User: Return agent message
    else Decision is to move to next step
        Session->>Session: Update current step
        Session->>LLM: Request next decision in new step
        LLM->>Session: Return decision
        Session->>User: Return agent message
    end"
/>

1. **User Input**: The user sends a message to the agent's session
2. **Decision Making**: The LLM evaluates the user input and current step to decide what to do
3. **Action Execution**: The session executes the decided action (speak, call tool, or move)
4. **Response**: The result is returned to the user

## Key Interfaces

SOFIA defines several key interfaces and base classes:

### `LLMBase`

The base class for all LLM providers:

```python
class LLMBase:
    def _get_output(self, name, steps, current_step, tools, history, response_format, system_message, persona):
        """Get the next decision from the LLM."""
        pass
```

### `Step` and `Route`

Define the flow structure:

```python
class Step:
    step_id: str
    description: str
    available_tools: Optional[List[str]] = []
    routes: Optional[List[Route]] = []

class Route:
    target: str
    condition: str
```

### `Tool`

Represents a callable tool:

```python
class Tool:
    name: str
    description: str
    parameters: Dict[str, Any]
    function: Callable

    def run(self, **kwargs):
        """Run the tool with the provided parameters."""
        pass
```

## Extension Points

SOFIA is designed to be extensible. Key extension points include:

1. **Custom Tools**: Create your own tools by defining Python functions
2. **Custom LLM Providers**: Implement the `LLMBase` interface
3. **Session Storage**: Implement custom session storage adapters
4. **Error Handling**: Customize error recovery mechanisms
5. **Middleware**: Add middleware for logging, monitoring, etc.

## Next Steps

- [Agent Flows](/docs/concepts/agent-flows): Learn more about steps and routes
- [Tools Integration](/docs/concepts/tools-integration): Understand how tools work
- [Session Management](/docs/concepts/session-management): Learn about session lifecycle
- [LLM Integration](/docs/concepts/llm-integration): Explore different LLM providers
